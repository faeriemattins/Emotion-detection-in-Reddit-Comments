{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **ENVIRONMENT SETUP**","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-07T02:25:04.295957Z","iopub.execute_input":"2022-10-07T02:25:04.297328Z","iopub.status.idle":"2022-10-07T02:25:05.680405Z","shell.execute_reply.started":"2022-10-07T02:25:04.297292Z","shell.execute_reply":"2022-10-07T02:25:05.678587Z"}}},{"cell_type":"code","source":"%cd /kaggle/working/\n! rm -rf emotion-classification\n! git clone https://github.com/srivarshan-s/emotion-classification.git\n%cd emotion-classification","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:26.750659Z","iopub.execute_input":"2022-10-09T07:57:26.751018Z","iopub.status.idle":"2022-10-09T07:57:34.596555Z","shell.execute_reply.started":"2022-10-09T07:57:26.750986Z","shell.execute_reply":"2022-10-09T07:57:34.595440Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'emotion-classification'...\nremote: Enumerating objects: 120, done.\u001b[K\nremote: Counting objects: 100% (7/7), done.\u001b[K\nremote: Compressing objects: 100% (7/7), done.\u001b[K\nremote: Total 120 (delta 0), reused 5 (delta 0), pack-reused 113\u001b[K\nReceiving objects: 100% (120/120), 101.64 MiB | 33.10 MiB/s, done.\nResolving deltas: 100% (7/7), done.\n/kaggle/working/emotion-classification\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **IMPORT LIBRARIES**","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport string\nimport json\nimport emoji\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pickle\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\npd.set_option(\"display.max_columns\", None)\n\nfrom sklearn import metrics\nfrom bs4 import BeautifulSoup\nimport transformers\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:34.599294Z","iopub.execute_input":"2022-10-09T07:57:34.599704Z","iopub.status.idle":"2022-10-09T07:57:42.952027Z","shell.execute_reply.started":"2022-10-09T07:57:34.599665Z","shell.execute_reply":"2022-10-09T07:57:42.950921Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### **LOAD DATASET**","metadata":{}},{"cell_type":"code","source":"# Load the testing and validations datasets\n\ndf_train = pd.read_csv(\"data/train.tsv\", sep='\\t', header=None, names=['Text', 'Class', 'ID'])\ndf_dev = pd.read_csv(\"data/dev.tsv\", sep='\\t', header=None, names=['Text', 'Class', 'ID'])","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:42.953403Z","iopub.execute_input":"2022-10-09T07:57:42.953772Z","iopub.status.idle":"2022-10-09T07:57:43.053372Z","shell.execute_reply.started":"2022-10-09T07:57:42.953727Z","shell.execute_reply":"2022-10-09T07:57:43.052466Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.054914Z","iopub.execute_input":"2022-10-09T07:57:43.055290Z","iopub.status.idle":"2022-10-09T07:57:43.073882Z","shell.execute_reply.started":"2022-10-09T07:57:43.055253Z","shell.execute_reply":"2022-10-09T07:57:43.073002Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                Text Class       ID\n0  My favourite food is anything I didn't have to...    27  eebbqej\n1  Now if he does off himself, everyone will thin...    27  ed00q6i\n2                     WHY THE FUCK IS BAYLESS ISOING     2  eezlygj\n3                        To make her feel threatened    14  ed7ypvh\n4                             Dirty Southern Wankers     3  ed0bdzj","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My favourite food is anything I didn't have to...</td>\n      <td>27</td>\n      <td>eebbqej</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Now if he does off himself, everyone will thin...</td>\n      <td>27</td>\n      <td>ed00q6i</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n      <td>2</td>\n      <td>eezlygj</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To make her feel threatened</td>\n      <td>14</td>\n      <td>ed7ypvh</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dirty Southern Wankers</td>\n      <td>3</td>\n      <td>ed0bdzj</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Obtain the Class List and Number of Classes\n\ndf_train['List of classes'] = df_train['Class'].apply(lambda x: x.split(','))\ndf_train['Len of classes'] = df_train['List of classes'].apply(lambda x: len(x))\n\ndf_dev['List of classes'] = df_dev['Class'].apply(lambda x: x.split(','))\ndf_dev['Len of classes'] = df_dev['List of classes'].apply(lambda x: len(x))","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.077972Z","iopub.execute_input":"2022-10-09T07:57:43.078864Z","iopub.status.idle":"2022-10-09T07:57:43.313132Z","shell.execute_reply.started":"2022-10-09T07:57:43.078821Z","shell.execute_reply":"2022-10-09T07:57:43.312189Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.314464Z","iopub.execute_input":"2022-10-09T07:57:43.315042Z","iopub.status.idle":"2022-10-09T07:57:43.330845Z","shell.execute_reply.started":"2022-10-09T07:57:43.315002Z","shell.execute_reply":"2022-10-09T07:57:43.330016Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                Text Class       ID  \\\n0  My favourite food is anything I didn't have to...    27  eebbqej   \n1  Now if he does off himself, everyone will thin...    27  ed00q6i   \n2                     WHY THE FUCK IS BAYLESS ISOING     2  eezlygj   \n3                        To make her feel threatened    14  ed7ypvh   \n4                             Dirty Southern Wankers     3  ed0bdzj   \n\n  List of classes  Len of classes  \n0            [27]               1  \n1            [27]               1  \n2             [2]               1  \n3            [14]               1  \n4             [3]               1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n      <th>ID</th>\n      <th>List of classes</th>\n      <th>Len of classes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My favourite food is anything I didn't have to...</td>\n      <td>27</td>\n      <td>eebbqej</td>\n      <td>[27]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Now if he does off himself, everyone will thin...</td>\n      <td>27</td>\n      <td>ed00q6i</td>\n      <td>[27]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n      <td>2</td>\n      <td>eezlygj</td>\n      <td>[2]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To make her feel threatened</td>\n      <td>14</td>\n      <td>ed7ypvh</td>\n      <td>[14]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dirty Southern Wankers</td>\n      <td>3</td>\n      <td>ed0bdzj</td>\n      <td>[3]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ekman mapping\n\nwith open('data/ekman_mapping.json') as file:\n    ekman_mapping = json.load(file)\n    \nekman_mapping","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.332063Z","iopub.execute_input":"2022-10-09T07:57:43.332506Z","iopub.status.idle":"2022-10-09T07:57:43.341539Z","shell.execute_reply.started":"2022-10-09T07:57:43.332466Z","shell.execute_reply":"2022-10-09T07:57:43.340329Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'anger': ['anger', 'annoyance', 'disapproval'],\n 'disgust': ['disgust'],\n 'fear': ['fear', 'nervousness'],\n 'joy': ['joy',\n  'amusement',\n  'approval',\n  'excitement',\n  'gratitude',\n  'love',\n  'optimism',\n  'relief',\n  'pride',\n  'admiration',\n  'desire',\n  'caring'],\n 'sadness': ['sadness', 'disappointment', 'embarrassment', 'grief', 'remorse'],\n 'surprise': ['surprise', 'realization', 'confusion', 'curiosity']}"},"metadata":{}}]},{"cell_type":"code","source":"# Load the list of original emotions\n\nemotion_file = open(\"data/emotions.txt\", \"r\")\nemotion_list = emotion_file.read()\nemotion_list = emotion_list.split(\"\\n\")\nprint(emotion_list)\nprint(f\"Number of Original Emotions = {len(emotion_list)}\")","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.343196Z","iopub.execute_input":"2022-10-09T07:57:43.343675Z","iopub.status.idle":"2022-10-09T07:57:43.355652Z","shell.execute_reply.started":"2022-10-09T07:57:43.343634Z","shell.execute_reply":"2022-10-09T07:57:43.354606Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\nNumber of Original Emotions = 28\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define function to convert class number to emotion\n\ndef idx2class(idx_list):\n    arr = []\n    for i in idx_list:\n        arr.append(emotion_list[int(i)])\n    return arr","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.358158Z","iopub.execute_input":"2022-10-09T07:57:43.359230Z","iopub.status.idle":"2022-10-09T07:57:43.364925Z","shell.execute_reply.started":"2022-10-09T07:57:43.359189Z","shell.execute_reply":"2022-10-09T07:57:43.363841Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_train['Emotions'] = df_train['List of classes'].apply(idx2class)\ndf_dev['Emotions'] = df_dev['List of classes'].apply(idx2class)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.366606Z","iopub.execute_input":"2022-10-09T07:57:43.367150Z","iopub.status.idle":"2022-10-09T07:57:43.410129Z","shell.execute_reply.started":"2022-10-09T07:57:43.367109Z","shell.execute_reply":"2022-10-09T07:57:43.409258Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.411690Z","iopub.execute_input":"2022-10-09T07:57:43.412033Z","iopub.status.idle":"2022-10-09T07:57:43.425516Z","shell.execute_reply.started":"2022-10-09T07:57:43.411998Z","shell.execute_reply":"2022-10-09T07:57:43.424576Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                Text Class       ID  \\\n0  My favourite food is anything I didn't have to...    27  eebbqej   \n1  Now if he does off himself, everyone will thin...    27  ed00q6i   \n2                     WHY THE FUCK IS BAYLESS ISOING     2  eezlygj   \n3                        To make her feel threatened    14  ed7ypvh   \n4                             Dirty Southern Wankers     3  ed0bdzj   \n\n  List of classes  Len of classes     Emotions  \n0            [27]               1    [neutral]  \n1            [27]               1    [neutral]  \n2             [2]               1      [anger]  \n3            [14]               1       [fear]  \n4             [3]               1  [annoyance]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n      <th>ID</th>\n      <th>List of classes</th>\n      <th>Len of classes</th>\n      <th>Emotions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My favourite food is anything I didn't have to...</td>\n      <td>27</td>\n      <td>eebbqej</td>\n      <td>[27]</td>\n      <td>1</td>\n      <td>[neutral]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Now if he does off himself, everyone will thin...</td>\n      <td>27</td>\n      <td>ed00q6i</td>\n      <td>[27]</td>\n      <td>1</td>\n      <td>[neutral]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n      <td>2</td>\n      <td>eezlygj</td>\n      <td>[2]</td>\n      <td>1</td>\n      <td>[anger]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To make her feel threatened</td>\n      <td>14</td>\n      <td>ed7ypvh</td>\n      <td>[14]</td>\n      <td>1</td>\n      <td>[fear]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dirty Southern Wankers</td>\n      <td>3</td>\n      <td>ed0bdzj</td>\n      <td>[3]</td>\n      <td>1</td>\n      <td>[annoyance]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Define function to map the emotions according to the ekman mapping\n\ndef EmotionMapping(emotion_list):\n    map_list = []\n    for i in emotion_list:\n        if i in ekman_mapping['anger']:\n            map_list.append('anger')\n        if i in ekman_mapping['disgust']:\n            map_list.append('disgust')\n        if i in ekman_mapping['fear']:\n            map_list.append('fear')\n        if i in ekman_mapping['joy']:\n            map_list.append('joy')\n        if i in ekman_mapping['sadness']:\n            map_list.append('sadness')\n        if i in ekman_mapping['surprise']:\n            map_list.append('surprise')\n        if i == 'neutral':\n            map_list.append('neutral')\n    return map_list","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.427104Z","iopub.execute_input":"2022-10-09T07:57:43.427761Z","iopub.status.idle":"2022-10-09T07:57:43.436117Z","shell.execute_reply.started":"2022-10-09T07:57:43.427725Z","shell.execute_reply":"2022-10-09T07:57:43.434990Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df_train['Mapped Emotions'] = df_train['Emotions'].apply(EmotionMapping)\ndf_dev['Mapped Emotions'] = df_dev['Emotions'].apply(EmotionMapping)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.438139Z","iopub.execute_input":"2022-10-09T07:57:43.438799Z","iopub.status.idle":"2022-10-09T07:57:43.509525Z","shell.execute_reply.started":"2022-10-09T07:57:43.438758Z","shell.execute_reply":"2022-10-09T07:57:43.508694Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.514527Z","iopub.execute_input":"2022-10-09T07:57:43.515282Z","iopub.status.idle":"2022-10-09T07:57:43.532226Z","shell.execute_reply.started":"2022-10-09T07:57:43.515247Z","shell.execute_reply":"2022-10-09T07:57:43.531338Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                                Text Class       ID  \\\n0  My favourite food is anything I didn't have to...    27  eebbqej   \n1  Now if he does off himself, everyone will thin...    27  ed00q6i   \n2                     WHY THE FUCK IS BAYLESS ISOING     2  eezlygj   \n3                        To make her feel threatened    14  ed7ypvh   \n4                             Dirty Southern Wankers     3  ed0bdzj   \n\n  List of classes  Len of classes     Emotions Mapped Emotions  \n0            [27]               1    [neutral]       [neutral]  \n1            [27]               1    [neutral]       [neutral]  \n2             [2]               1      [anger]         [anger]  \n3            [14]               1       [fear]          [fear]  \n4             [3]               1  [annoyance]         [anger]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n      <th>ID</th>\n      <th>List of classes</th>\n      <th>Len of classes</th>\n      <th>Emotions</th>\n      <th>Mapped Emotions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My favourite food is anything I didn't have to...</td>\n      <td>27</td>\n      <td>eebbqej</td>\n      <td>[27]</td>\n      <td>1</td>\n      <td>[neutral]</td>\n      <td>[neutral]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Now if he does off himself, everyone will thin...</td>\n      <td>27</td>\n      <td>ed00q6i</td>\n      <td>[27]</td>\n      <td>1</td>\n      <td>[neutral]</td>\n      <td>[neutral]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n      <td>2</td>\n      <td>eezlygj</td>\n      <td>[2]</td>\n      <td>1</td>\n      <td>[anger]</td>\n      <td>[anger]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To make her feel threatened</td>\n      <td>14</td>\n      <td>ed7ypvh</td>\n      <td>[14]</td>\n      <td>1</td>\n      <td>[fear]</td>\n      <td>[fear]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dirty Southern Wankers</td>\n      <td>3</td>\n      <td>ed0bdzj</td>\n      <td>[3]</td>\n      <td>1</td>\n      <td>[annoyance]</td>\n      <td>[anger]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Create columns for the new mapped emotions\n\ndf_train['anger'] = np.zeros((len(df_train),1))\ndf_train['disgust'] = np.zeros((len(df_train),1))\ndf_train['fear'] = np.zeros((len(df_train),1))\ndf_train['joy'] = np.zeros((len(df_train),1))\ndf_train['sadness'] = np.zeros((len(df_train),1))\ndf_train['surprise'] = np.zeros((len(df_train),1))\ndf_train['neutral'] = np.zeros((len(df_train),1))\n\ndf_dev['anger'] = np.zeros((len(df_dev),1))\ndf_dev['disgust'] = np.zeros((len(df_dev),1))\ndf_dev['fear'] = np.zeros((len(df_dev),1))\ndf_dev['joy'] = np.zeros((len(df_dev),1))\ndf_dev['sadness'] = np.zeros((len(df_dev),1))\ndf_dev['surprise'] = np.zeros((len(df_dev),1))\ndf_dev['neutral'] = np.zeros((len(df_dev),1))\n\n# Fill the column with the corresponding emotions\nfor i in ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise','neutral']:\n    df_train[i] = df_train['Mapped Emotions'].apply(lambda x: 1 if i in x else 0)\n    df_dev[i] = df_dev['Mapped Emotions'].apply(lambda x: 1 if i in x else 0)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.533302Z","iopub.execute_input":"2022-10-09T07:57:43.533577Z","iopub.status.idle":"2022-10-09T07:57:43.671248Z","shell.execute_reply.started":"2022-10-09T07:57:43.533553Z","shell.execute_reply":"2022-10-09T07:57:43.670390Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.672651Z","iopub.execute_input":"2022-10-09T07:57:43.672976Z","iopub.status.idle":"2022-10-09T07:57:43.690252Z","shell.execute_reply.started":"2022-10-09T07:57:43.672942Z","shell.execute_reply":"2022-10-09T07:57:43.689347Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                                Text Class       ID  \\\n0  My favourite food is anything I didn't have to...    27  eebbqej   \n1  Now if he does off himself, everyone will thin...    27  ed00q6i   \n2                     WHY THE FUCK IS BAYLESS ISOING     2  eezlygj   \n3                        To make her feel threatened    14  ed7ypvh   \n4                             Dirty Southern Wankers     3  ed0bdzj   \n\n  List of classes  Len of classes     Emotions Mapped Emotions  anger  \\\n0            [27]               1    [neutral]       [neutral]      0   \n1            [27]               1    [neutral]       [neutral]      0   \n2             [2]               1      [anger]         [anger]      1   \n3            [14]               1       [fear]          [fear]      0   \n4             [3]               1  [annoyance]         [anger]      1   \n\n   disgust  fear  joy  sadness  surprise  neutral  \n0        0     0    0        0         0        1  \n1        0     0    0        0         0        1  \n2        0     0    0        0         0        0  \n3        0     1    0        0         0        0  \n4        0     0    0        0         0        0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n      <th>ID</th>\n      <th>List of classes</th>\n      <th>Len of classes</th>\n      <th>Emotions</th>\n      <th>Mapped Emotions</th>\n      <th>anger</th>\n      <th>disgust</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My favourite food is anything I didn't have to...</td>\n      <td>27</td>\n      <td>eebbqej</td>\n      <td>[27]</td>\n      <td>1</td>\n      <td>[neutral]</td>\n      <td>[neutral]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Now if he does off himself, everyone will thin...</td>\n      <td>27</td>\n      <td>ed00q6i</td>\n      <td>[27]</td>\n      <td>1</td>\n      <td>[neutral]</td>\n      <td>[neutral]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n      <td>2</td>\n      <td>eezlygj</td>\n      <td>[2]</td>\n      <td>1</td>\n      <td>[anger]</td>\n      <td>[anger]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To make her feel threatened</td>\n      <td>14</td>\n      <td>ed7ypvh</td>\n      <td>[14]</td>\n      <td>1</td>\n      <td>[fear]</td>\n      <td>[fear]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dirty Southern Wankers</td>\n      <td>3</td>\n      <td>ed0bdzj</td>\n      <td>[3]</td>\n      <td>1</td>\n      <td>[annoyance]</td>\n      <td>[anger]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_dev.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.691760Z","iopub.execute_input":"2022-10-09T07:57:43.692339Z","iopub.status.idle":"2022-10-09T07:57:43.715671Z","shell.execute_reply.started":"2022-10-09T07:57:43.692303Z","shell.execute_reply":"2022-10-09T07:57:43.714321Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                Text Class       ID  \\\n0  Is this in New Orleans?? I really feel like th...    27  edgurhb   \n1  You know the answer man, you are programmed to...  4,27  ee84bjg   \n2               I've never been this sad in my life!    25  edcu99z   \n3  The economy is heavily controlled and subsidiz...  4,27  edc32e2   \n4  He could have easily taken a real camera from ...    20  eepig6r   \n\n  List of classes  Len of classes             Emotions Mapped Emotions  anger  \\\n0            [27]               1            [neutral]       [neutral]      0   \n1         [4, 27]               2  [approval, neutral]  [joy, neutral]      0   \n2            [25]               1            [sadness]       [sadness]      0   \n3         [4, 27]               2  [approval, neutral]  [joy, neutral]      0   \n4            [20]               1           [optimism]           [joy]      0   \n\n   disgust  fear  joy  sadness  surprise  neutral  \n0        0     0    0        0         0        1  \n1        0     0    1        0         0        1  \n2        0     0    0        1         0        0  \n3        0     0    1        0         0        1  \n4        0     0    1        0         0        0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n      <th>ID</th>\n      <th>List of classes</th>\n      <th>Len of classes</th>\n      <th>Emotions</th>\n      <th>Mapped Emotions</th>\n      <th>anger</th>\n      <th>disgust</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Is this in New Orleans?? I really feel like th...</td>\n      <td>27</td>\n      <td>edgurhb</td>\n      <td>[27]</td>\n      <td>1</td>\n      <td>[neutral]</td>\n      <td>[neutral]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>You know the answer man, you are programmed to...</td>\n      <td>4,27</td>\n      <td>ee84bjg</td>\n      <td>[4, 27]</td>\n      <td>2</td>\n      <td>[approval, neutral]</td>\n      <td>[joy, neutral]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I've never been this sad in my life!</td>\n      <td>25</td>\n      <td>edcu99z</td>\n      <td>[25]</td>\n      <td>1</td>\n      <td>[sadness]</td>\n      <td>[sadness]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The economy is heavily controlled and subsidiz...</td>\n      <td>4,27</td>\n      <td>edc32e2</td>\n      <td>[4, 27]</td>\n      <td>2</td>\n      <td>[approval, neutral]</td>\n      <td>[joy, neutral]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>He could have easily taken a real camera from ...</td>\n      <td>20</td>\n      <td>eepig6r</td>\n      <td>[20]</td>\n      <td>1</td>\n      <td>[optimism]</td>\n      <td>[joy]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Drop rows with more than 1 emotion\n\ndf_train.drop(df_train[df_train[\"Len of classes\"] > 1].index, axis=0, inplace=True)\ndf_dev.drop(df_dev[df_dev[\"Len of classes\"] > 1].index, axis=0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.717179Z","iopub.execute_input":"2022-10-09T07:57:43.718047Z","iopub.status.idle":"2022-10-09T07:57:43.750534Z","shell.execute_reply.started":"2022-10-09T07:57:43.718002Z","shell.execute_reply":"2022-10-09T07:57:43.749596Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Drop rows with neutral and disgust emotions\n\n# df_train.drop(df_train[df_train['neutral'] == 1].index, inplace=True)\n# df_dev.drop(df_dev[df_dev['neutral'] == 1].index, inplace=True)\n# df_train.drop(df_train[df_train['disgust'] == 1].index, inplace=True)\n# df_dev.drop(df_dev[df_dev['disgust'] == 1].index, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.752050Z","iopub.execute_input":"2022-10-09T07:57:43.752410Z","iopub.status.idle":"2022-10-09T07:57:43.758025Z","shell.execute_reply.started":"2022-10-09T07:57:43.752374Z","shell.execute_reply":"2022-10-09T07:57:43.756763Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Drop extra columns\n\n# df_train.drop(['Class', 'List of classes', 'Len of classes', 'Emotions', 'Mapped Emotions', 'neutral', 'disgust'], axis=1, inplace=True)\n# df_dev.drop(['Class', 'List of classes', 'Len of classes', 'Emotions', 'Mapped Emotions', 'neutral', 'disgust'], axis=1, inplace=True)\n\ndf_train.drop(['Class', 'List of classes', 'Len of classes', 'Emotions', 'Mapped Emotions'], axis=1, inplace=True)\ndf_dev.drop(['Class', 'List of classes', 'Len of classes', 'Emotions', 'Mapped Emotions'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.759828Z","iopub.execute_input":"2022-10-09T07:57:43.760253Z","iopub.status.idle":"2022-10-09T07:57:43.772441Z","shell.execute_reply.started":"2022-10-09T07:57:43.760219Z","shell.execute_reply":"2022-10-09T07:57:43.771406Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.774084Z","iopub.execute_input":"2022-10-09T07:57:43.774821Z","iopub.status.idle":"2022-10-09T07:57:43.791449Z","shell.execute_reply.started":"2022-10-09T07:57:43.774782Z","shell.execute_reply":"2022-10-09T07:57:43.790329Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                                                Text       ID  anger  disgust  \\\n0  My favourite food is anything I didn't have to...  eebbqej      0        0   \n1  Now if he does off himself, everyone will thin...  ed00q6i      0        0   \n2                     WHY THE FUCK IS BAYLESS ISOING  eezlygj      1        0   \n3                        To make her feel threatened  ed7ypvh      0        0   \n4                             Dirty Southern Wankers  ed0bdzj      1        0   \n\n   fear  joy  sadness  surprise  neutral  \n0     0    0        0         0        1  \n1     0    0        0         0        1  \n2     0    0        0         0        0  \n3     1    0        0         0        0  \n4     0    0        0         0        0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>ID</th>\n      <th>anger</th>\n      <th>disgust</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My favourite food is anything I didn't have to...</td>\n      <td>eebbqej</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Now if he does off himself, everyone will thin...</td>\n      <td>ed00q6i</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n      <td>eezlygj</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To make her feel threatened</td>\n      <td>ed7ypvh</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dirty Southern Wankers</td>\n      <td>ed0bdzj</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### **DATA PREPROCESSING**","metadata":{}},{"cell_type":"code","source":"# Mapping for expansion of contracted words\n\ncontraction_mapping = {\n    \"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \n    \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \n    \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \n    \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n    \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \n    \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \n    \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n    \"might've\": \"might have\",\"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \n    \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n    \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \n    \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \n    \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n    \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \n    \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n    \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \n    \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n    \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \n    \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n    \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n    \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n    \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \n    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n    \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\",\n    \"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n    \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'u.s':'america', \n    'e.g':'for example'\n}\n\n# Function to expand the contractions\n\ndef clean_contractions(text, mapping):\n    '''Clean contraction using contraction mapping'''    \n    # Uniform apostrophe\n    specials = [\"’\", \"‘\", \"´\", \"`\"]\n    for s in specials:\n        text = text.replace(s, \"'\")\n        \n    # Expand the words using mapping\n    for word in mapping.keys():\n        if \"\"+word+\"\" in text:\n            text = text.replace(\"\"+word+\"\", \"\"+mapping[word]+\"\")\n            \n    # Remove Punctuations\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # Create space b/w word and punctuation following it\n    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n    text = re.sub(r'[\" \"]+', \" \", text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.793380Z","iopub.execute_input":"2022-10-09T07:57:43.794140Z","iopub.status.idle":"2022-10-09T07:57:43.996217Z","shell.execute_reply.started":"2022-10-09T07:57:43.794102Z","shell.execute_reply":"2022-10-09T07:57:43.994938Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# List of punctuations\n\npunct = [\n    ',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',\n    '~', '@', '£', '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', \n    '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', \n    '—', '‹', '─', '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', \n    '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', \n    '‡', '√', \n]\n\n# Mapping for punctuations\n\npunct_mapping = {\n    \"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\",\n    \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', \n    'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '!':' '\n}","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:43.997788Z","iopub.execute_input":"2022-10-09T07:57:43.998165Z","iopub.status.idle":"2022-10-09T07:57:44.011480Z","shell.execute_reply.started":"2022-10-09T07:57:43.998128Z","shell.execute_reply":"2022-10-09T07:57:44.010497Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Dictionary to correct the misspellings\n\nmispell_dict = {\n    'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', \n    'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', \n    'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', \n    'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', \n    'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \n    \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', \n    '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', \n    'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'\n}\n\n# Function to correct the misspellings\n\ndef correct_spelling(x, dic):\n    for word in dic.keys():\n        x = x.replace(word, dic[word])\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:44.014171Z","iopub.execute_input":"2022-10-09T07:57:44.014857Z","iopub.status.idle":"2022-10-09T07:57:44.027372Z","shell.execute_reply.started":"2022-10-09T07:57:44.014804Z","shell.execute_reply":"2022-10-09T07:57:44.026194Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Function to clean the text\n\ndef clean_text(text):\n    text = emoji.demojize(text) # Remove emojis\n    text = re.sub(r'\\:(.*?)\\:','',text) \n    text = str(text).lower() # Make text lowercase\n    text = re.sub('\\[.*?\\]', '', text) # Remove text inside square brackets\n    text = BeautifulSoup(text, 'lxml').get_text() # Remove html\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # Remove links\n    text = re.sub('<.*?>+', '', text) # Remove text inside angular brackets\n    text = re.sub('\\n', '', text) # Remove newlines\n    text = re.sub('\\w*\\d\\w*', '', text) # Remove words that contain numbers\n    # Replace everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\")\n    text = re.sub(r\"[^a-zA-Z?.!,¿']+\", \" \", text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:44.031028Z","iopub.execute_input":"2022-10-09T07:57:44.031305Z","iopub.status.idle":"2022-10-09T07:57:44.040006Z","shell.execute_reply.started":"2022-10-09T07:57:44.031270Z","shell.execute_reply":"2022-10-09T07:57:44.039063Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Function to remove any special characters\n\ndef clean_special_chars(text, punct, mapping):\n    for p in mapping:\n        text = text.replace(p, mapping[p])\n    for p in punct:\n        text = text.replace(p, f' {p} ')\n    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''} # List of special characters\n    for s in specials:\n        text = text.replace(s, specials[s])\n    return text\n\n# Function to remove any extra spaces\n\ndef remove_space(text):\n    text = text.strip()\n    text = text.split()\n    return \" \".join(text)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:44.042401Z","iopub.execute_input":"2022-10-09T07:57:44.043076Z","iopub.status.idle":"2022-10-09T07:57:44.051281Z","shell.execute_reply.started":"2022-10-09T07:57:44.043038Z","shell.execute_reply":"2022-10-09T07:57:44.050323Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Function to perform the entire preprocessing\n\ndef text_preprocessing_pipeline(text):\n    text = clean_text(text)\n    text = clean_contractions(text, contraction_mapping)\n    text = clean_special_chars(text, punct, punct_mapping)\n    text = correct_spelling(text, mispell_dict)\n    text = remove_space(text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:44.054771Z","iopub.execute_input":"2022-10-09T07:57:44.055017Z","iopub.status.idle":"2022-10-09T07:57:44.063092Z","shell.execute_reply.started":"2022-10-09T07:57:44.054994Z","shell.execute_reply":"2022-10-09T07:57:44.062144Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Apply preprocessing\n\ndf_train['Text'] = df_train['Text'].apply(text_preprocessing_pipeline)\ndf_dev['Text'] = df_dev['Text'].apply(text_preprocessing_pipeline)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:44.064544Z","iopub.execute_input":"2022-10-09T07:57:44.068346Z","iopub.status.idle":"2022-10-09T07:57:58.993340Z","shell.execute_reply.started":"2022-10-09T07:57:44.068318Z","shell.execute_reply":"2022-10-09T07:57:58.992210Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Reset the Indices\n\ndf_train = df_train.reset_index(drop=True)\ndf_dev = df_dev.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:58.994618Z","iopub.execute_input":"2022-10-09T07:57:58.995804Z","iopub.status.idle":"2022-10-09T07:57:59.002466Z","shell.execute_reply.started":"2022-10-09T07:57:58.995763Z","shell.execute_reply":"2022-10-09T07:57:59.001537Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:59.003776Z","iopub.execute_input":"2022-10-09T07:57:59.004410Z","iopub.status.idle":"2022-10-09T07:57:59.039404Z","shell.execute_reply.started":"2022-10-09T07:57:59.004370Z","shell.execute_reply":"2022-10-09T07:57:59.038328Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                                                Text       ID  anger  disgust  \\\n0  my favorite food is anything i did not have to...  eebbqej      0        0   \n1  now if he does off himself everyone will think...  ed00q6i      0        0   \n2                     why the fuck is bayless isoing  eezlygj      1        0   \n3                        to make her feel threatened  ed7ypvh      0        0   \n4                             dirty southern wankers  ed0bdzj      1        0   \n\n   fear  joy  sadness  surprise  neutral  \n0     0    0        0         0        1  \n1     0    0        0         0        1  \n2     0    0        0         0        0  \n3     1    0        0         0        0  \n4     0    0        0         0        0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>ID</th>\n      <th>anger</th>\n      <th>disgust</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>my favorite food is anything i did not have to...</td>\n      <td>eebbqej</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>now if he does off himself everyone will think...</td>\n      <td>ed00q6i</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>why the fuck is bayless isoing</td>\n      <td>eezlygj</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>to make her feel threatened</td>\n      <td>ed7ypvh</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dirty southern wankers</td>\n      <td>ed0bdzj</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_dev.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:59.040741Z","iopub.execute_input":"2022-10-09T07:57:59.041076Z","iopub.status.idle":"2022-10-09T07:57:59.055891Z","shell.execute_reply.started":"2022-10-09T07:57:59.041039Z","shell.execute_reply":"2022-10-09T07:57:59.054947Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"                                                Text       ID  anger  disgust  \\\n0  is this in new orleans i really feel like this...  edgurhb      0        0   \n1              i have never been this sad in my life  edcu99z      0        0   \n2  he could have easily taken a real camera from ...  eepig6r      0        0   \n3  thank you for your vote of confidence but we s...  eczm50f      0        0   \n4  wah mum other people call me on my bullshit an...  ed4yr9r      1        0   \n\n   fear  joy  sadness  surprise  neutral  \n0     0    0        0         0        1  \n1     0    0        1         0        0  \n2     0    1        0         0        0  \n3     0    1        0         0        0  \n4     0    0        0         0        0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>ID</th>\n      <th>anger</th>\n      <th>disgust</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>is this in new orleans i really feel like this...</td>\n      <td>edgurhb</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i have never been this sad in my life</td>\n      <td>edcu99z</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>he could have easily taken a real camera from ...</td>\n      <td>eepig6r</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>thank you for your vote of confidence but we s...</td>\n      <td>eczm50f</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>wah mum other people call me on my bullshit an...</td>\n      <td>ed4yr9r</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(df_train.shape)\nprint(df_dev.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:59.057352Z","iopub.execute_input":"2022-10-09T07:57:59.057986Z","iopub.status.idle":"2022-10-09T07:57:59.066455Z","shell.execute_reply.started":"2022-10-09T07:57:59.057940Z","shell.execute_reply":"2022-10-09T07:57:59.064335Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"(36308, 9)\n(4548, 9)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **PRE-CONFIG FOR BERT**","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:59.068156Z","iopub.execute_input":"2022-10-09T07:57:59.068805Z","iopub.status.idle":"2022-10-09T07:57:59.131391Z","shell.execute_reply.started":"2022-10-09T07:57:59.068769Z","shell.execute_reply":"2022-10-09T07:57:59.130416Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 200\nTRAIN_BATCH_SIZE = 64\nVALID_BATCH_SIZE = 64\nEPOCHS = 10\nLEARNING_RATE = 2e-5","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:59.135002Z","iopub.execute_input":"2022-10-09T07:57:59.135419Z","iopub.status.idle":"2022-10-09T07:57:59.140734Z","shell.execute_reply.started":"2022-10-09T07:57:59.135280Z","shell.execute_reply":"2022-10-09T07:57:59.139825Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### **BUILD DATASET FOR BERT**","metadata":{}},{"cell_type":"code","source":"# Load Tokenizer\ntokenizer = AutoTokenizer.from_pretrained('roberta-base')\n\n# Extract Target Labels\ntarget_labels = [col for col in df_train.columns if col not in ['Text', 'ID']]","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:57:59.142212Z","iopub.execute_input":"2022-10-09T07:57:59.142927Z","iopub.status.idle":"2022-10-09T07:58:05.051122Z","shell.execute_reply.started":"2022-10-09T07:57:59.142892Z","shell.execute_reply":"2022-10-09T07:58:05.050160Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15edf0d2940e4101b3887891c40c9c29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a3c6dc846254b1b99a53437de4d5641"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a676921c3a704a0f9a336fdd6345b439"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68815290e9fc4ace84c0cc93605ea401"}},"metadata":{}}]},{"cell_type":"code","source":"print(f\"The target labels are : {target_labels}\")","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:58:05.052727Z","iopub.execute_input":"2022-10-09T07:58:05.053112Z","iopub.status.idle":"2022-10-09T07:58:05.058699Z","shell.execute_reply.started":"2022-10-09T07:58:05.053075Z","shell.execute_reply":"2022-10-09T07:58:05.057535Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"The target labels are : ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define class for dataset\n\nclass BertDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.max_len = max_len\n        self.text = df.Text\n        self.tokenizer = tokenizer\n        self.targets = df[target_labels].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:58:05.060587Z","iopub.execute_input":"2022-10-09T07:58:05.060980Z","iopub.status.idle":"2022-10-09T07:58:05.071809Z","shell.execute_reply.started":"2022-10-09T07:58:05.060945Z","shell.execute_reply":"2022-10-09T07:58:05.070322Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Create Dataset for both training and validation\n\ntrain_dataset = BertDataset(df_train, tokenizer, MAX_LEN)\nvalid_dataset = BertDataset(df_dev, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:58:05.073251Z","iopub.execute_input":"2022-10-09T07:58:05.073630Z","iopub.status.idle":"2022-10-09T07:58:05.085992Z","shell.execute_reply.started":"2022-10-09T07:58:05.073572Z","shell.execute_reply":"2022-10-09T07:58:05.085036Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Create DataLoader for training and validation\n\ntrain_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, \n                          num_workers=4, shuffle=True, pin_memory=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=VALID_BATCH_SIZE, \n                          num_workers=4, shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:58:05.087243Z","iopub.execute_input":"2022-10-09T07:58:05.087716Z","iopub.status.idle":"2022-10-09T07:58:05.096593Z","shell.execute_reply.started":"2022-10-09T07:58:05.087678Z","shell.execute_reply":"2022-10-09T07:58:05.095565Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"### **BUILD CUSTOM MODEL**","metadata":{}},{"cell_type":"code","source":"# Create class for custom model\n\nclass CustomModel(torch.nn.Module):\n    \n    def __init__(self):\n        super(CustomModel, self).__init__()\n        self.roberta = AutoModel.from_pretrained('roberta-base') # Load RoBerta model\n#         self.fc = torch.nn.Linear(768,5) # Connect to fully-connected layer for output\n        self.fc = torch.nn.Linear(768,7) # Connect to fully-connected layer for output\n    \n    def forward(self, ids, mask, token_type_ids):\n        _, features = self.roberta(ids, attention_mask = mask, \n                                   token_type_ids = token_type_ids, return_dict=False)\n        output = self.fc(features)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:58:05.098103Z","iopub.execute_input":"2022-10-09T07:58:05.098470Z","iopub.status.idle":"2022-10-09T07:58:05.107542Z","shell.execute_reply.started":"2022-10-09T07:58:05.098435Z","shell.execute_reply":"2022-10-09T07:58:05.106493Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Load custom model\n\nmodel = CustomModel().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:58:05.114348Z","iopub.execute_input":"2022-10-09T07:58:05.114654Z","iopub.status.idle":"2022-10-09T07:58:24.372944Z","shell.execute_reply.started":"2022-10-09T07:58:05.114625Z","shell.execute_reply":"2022-10-09T07:58:24.371906Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7db50153a55542b087fb3a57d169924e"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **TRAIN CUSTOM BERT MODEL**","metadata":{}},{"cell_type":"code","source":"loss_fn = torch.nn.BCEWithLogitsLoss() # Loss function\noptimizer = AdamW(params =  model.parameters(), lr=LEARNING_RATE, weight_decay=1e-6) # Optimizer","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:58:24.374592Z","iopub.execute_input":"2022-10-09T07:58:24.374984Z","iopub.status.idle":"2022-10-09T07:58:24.384989Z","shell.execute_reply.started":"2022-10-09T07:58:24.374935Z","shell.execute_reply":"2022-10-09T07:58:24.383879Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Define function to train the model\n\ndef train(epoch):\n    \n    model.train()\n    \n    for _, data in enumerate(train_loader, 0):\n        \n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.float)\n\n        outputs = model(ids, mask, token_type_ids)\n\n        loss = loss_fn(outputs, targets)\n        \n#         if _ % 500 == 0:\n#             print(f'Epoch: {epoch + 1}, Loss:  {loss.item()}')\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n    print(f'Epoch: {epoch + 1}, Loss:  {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:58:24.386592Z","iopub.execute_input":"2022-10-09T07:58:24.387036Z","iopub.status.idle":"2022-10-09T07:58:24.395386Z","shell.execute_reply.started":"2022-10-09T07:58:24.386944Z","shell.execute_reply":"2022-10-09T07:58:24.394138Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Perform model training\n\nfor epoch in range(EPOCHS):\n# for epoch in range(1):\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T07:58:24.397082Z","iopub.execute_input":"2022-10-09T07:58:24.397533Z","iopub.status.idle":"2022-10-09T09:43:29.452211Z","shell.execute_reply.started":"2022-10-09T07:58:24.397434Z","shell.execute_reply":"2022-10-09T09:43:29.451079Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Epoch: 1, Loss:  0.20336589217185974\nEpoch: 2, Loss:  0.24591010808944702\nEpoch: 3, Loss:  0.23236705362796783\nEpoch: 4, Loss:  0.11677656322717667\nEpoch: 5, Loss:  0.14026693999767303\nEpoch: 6, Loss:  0.10517556220293045\nEpoch: 7, Loss:  0.11188917607069016\nEpoch: 8, Loss:  0.16031482815742493\nEpoch: 9, Loss:  0.013923891820013523\nEpoch: 10, Loss:  0.08216524124145508\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **EVALUATE CUSTOM BERT MODEL**","metadata":{}},{"cell_type":"code","source":"# Define function for model evaluation\n\ndef validation(data_loader):\n    \n    model.eval()\n    fin_targets = []\n    fin_outputs = []\n    \n    with torch.no_grad():\n        \n        for _, data in enumerate(data_loader, 0):\n            \n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            \n            outputs = model(ids, mask, token_type_ids)\n            \n            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n            \n    return fin_outputs, fin_targets","metadata":{"execution":{"iopub.status.busy":"2022-10-09T09:43:29.454410Z","iopub.execute_input":"2022-10-09T09:43:29.454715Z","iopub.status.idle":"2022-10-09T09:43:29.462424Z","shell.execute_reply.started":"2022-10-09T09:43:29.454682Z","shell.execute_reply":"2022-10-09T09:43:29.461400Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Perform model evaluation\n\noutputs, targets = validation(valid_loader)\n\noutputs = np.array(outputs) >= 0.5\n\naccuracy = metrics.accuracy_score(targets, outputs)\nf1_score_micro = metrics.f1_score(targets, outputs, average='micro')\nf1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n\nprint(f\"Accuracy Score = {accuracy}\")\nprint(f\"F1 Score (Micro) = {f1_score_micro}\")\nprint(f\"F1 Score (Macro) = {f1_score_macro}\")\n\nprint(metrics.classification_report(targets, outputs))","metadata":{"execution":{"iopub.status.busy":"2022-10-09T09:43:29.464195Z","iopub.execute_input":"2022-10-09T09:43:29.465063Z","iopub.status.idle":"2022-10-09T09:43:55.630072Z","shell.execute_reply.started":"2022-10-09T09:43:29.465026Z","shell.execute_reply":"2022-10-09T09:43:55.628208Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Accuracy Score = 0.6539138082673702\nF1 Score (Micro) = 0.6688275399575276\nF1 Score (Macro) = 0.5935260378242055\n              precision    recall  f1-score   support\n\n           0       0.51      0.53      0.52       485\n           1       0.42      0.44      0.43        61\n           2       0.70      0.64      0.67        66\n           3       0.79      0.84      0.81      1668\n           4       0.53      0.63      0.58       241\n           5       0.54      0.52      0.53       435\n           6       0.69      0.56      0.62      1592\n\n   micro avg       0.68      0.66      0.67      4548\n   macro avg       0.60      0.59      0.59      4548\nweighted avg       0.68      0.66      0.67      4548\n samples avg       0.66      0.66      0.66      4548\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Perform model evaluation on training data\n\noutputs, targets = validation(train_loader)\n\noutputs = np.array(outputs) >= 0.5\n\naccuracy = metrics.accuracy_score(targets, outputs)\nf1_score_micro = metrics.f1_score(targets, outputs, average='micro')\nf1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n\nprint(f\"Accuracy Score = {accuracy}\")\nprint(f\"F1 Score (Micro) = {f1_score_micro}\")\nprint(f\"F1 Score (Macro) = {f1_score_macro}\")\n\nprint(metrics.classification_report(targets, outputs))","metadata":{"execution":{"iopub.status.busy":"2022-10-09T09:43:55.632447Z","iopub.execute_input":"2022-10-09T09:43:55.633188Z","iopub.status.idle":"2022-10-09T09:47:22.399387Z","shell.execute_reply.started":"2022-10-09T09:43:55.633139Z","shell.execute_reply":"2022-10-09T09:47:22.398208Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Accuracy Score = 0.9717693070397708\nF1 Score (Micro) = 0.9758064516129032\nF1 Score (Macro) = 0.9637510580383475\n              precision    recall  f1-score   support\n\n           0       0.96      0.97      0.97      3878\n           1       0.91      0.92      0.91       498\n           2       0.98      0.96      0.97       515\n           3       0.98      0.99      0.99     12920\n           4       0.95      0.98      0.97      2121\n           5       0.96      0.96      0.96      3553\n           6       0.99      0.96      0.98     12823\n\n   micro avg       0.98      0.97      0.98     36308\n   macro avg       0.96      0.96      0.96     36308\nweighted avg       0.98      0.97      0.98     36308\n samples avg       0.97      0.97      0.97     36308\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **SAVE MODEL**","metadata":{}},{"cell_type":"code","source":"pickle.dump(model, open(\"../cust_bert_model.pkl\", \"wb\"))\npickle.dump(model, open(\"cust_bert_model.pkl\", \"wb\"))","metadata":{"execution":{"iopub.status.busy":"2022-10-09T09:47:22.401372Z","iopub.execute_input":"2022-10-09T09:47:22.401820Z","iopub.status.idle":"2022-10-09T09:47:24.439248Z","shell.execute_reply.started":"2022-10-09T09:47:22.401775Z","shell.execute_reply":"2022-10-09T09:47:24.438241Z"},"trusted":true},"execution_count":49,"outputs":[]}]}